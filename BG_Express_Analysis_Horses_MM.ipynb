{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from pprint import pprint\n",
    "from sklearn.manifold import TSNE\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "from sklearn.preprocessing import normalize\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reading CSV files\n",
    "\n",
    "optim_f_df=pd.read_csv('data/BGEIDSC.EF2EFFP.csv')                   # fuel optimization \n",
    "trans_f_df=pd.read_csv('data/BGETCHDATA.PTCHTRANH.csv')              # fuel transactions\n",
    "event_f_df=pd.read_csv('data/Extranet2.ExactFuelEvents.csv')         # fuel events\n",
    "level_f_df=pd.read_csv('data/Extranet2.ExactFuelTankLevels.csv')     # fuel levels\n",
    "truck_v_df=pd.read_csv('data/IBGEFILE.UNITS.csv')                    # trucks \n",
    "perfo_v_df=pd.read_csv('data/Extranet2.QCPerformanceExtracts.csv')   # vehicle performance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overviewing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_f_df.head(1)\n",
    "level_f_df.head()\n",
    "\n",
    "#optim_f_df.head(3)\n",
    "\n",
    "# TRUCK     Unit Number               *****                                           [TU]\n",
    "# ACTIVE    Active Flag (for fuel optimization)\n",
    "# SENDFUEL  Send Fuel Flag (for fuel optimization)\n",
    "# SENDROUTE Send Route Flag (for fuel optimization)\n",
    "# TANKCAP   Tank Capacity (gallons)                                       * 5 types\n",
    "# AVGMPG    MPG used for Fuel optimization (real value is closer to 7mpg)\n",
    "\n",
    "\n",
    "#trans_f_df.head(3)\n",
    "\n",
    "# TRNID   Transaction ID \n",
    "# TRNDAT  Transaction Date (YYYYMMDD)\n",
    "# TRNTIM  Transaction Time (HHMM)\n",
    "# TRNTS#  Station ID\n",
    "# TRNTSN  Station Name\n",
    "# TRNSTC  Station City\n",
    "# TRNST   Station State\n",
    "# TRNDRI  Driver Code                                                          [DR]\n",
    "# TRNUNT  Unit ID                                                              [TU]\n",
    "# TRNPI1  Item Code 1\n",
    "# TRNPQ1  Item Quantity 1\n",
    "# TRNPI2  Item Code 2\n",
    "# TRNPQ2  Item Quantity 2\n",
    "# TRNPI3  Item Code 3\n",
    "# TRNPQ3  Item Quantity 3\n",
    "# TRNPI4  Item Code 4\n",
    "# TRNPQ4  Item Quantity 4\n",
    "# TRNPI5  Item Code 5\n",
    "# TRNPQ5  Item Quantity 5\n",
    "# TRNPI6  Item Code 6\n",
    "# TRNPQ6  Item Quantity 6\n",
    "\n",
    "# Actual fuel transactions will have an item code of ULSD or FUEL, CDSL, DSL1, BDSL, \n",
    "# and could be in any of the Item slots 1-6\n",
    "\n",
    "level_f_df.head(3)\n",
    "\n",
    "# Id                AutoNumber id\n",
    "# TankId            Tank Sensor #         (for our trucks, will always be 1)\n",
    "# TankLevelPercent  Percentage Reading    0-100.00\n",
    "# TankLevelGallons  Gallons               (Percentage * Tank Capacity) (calculated)\n",
    "# ExactFuelEventId  Foreign Key to ExactFuelEvent                                       [EV]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block creates a list of truck IDs as numeric values (valid_trucks).\n",
    "\n",
    "good_trux_3 = optim_f_df['TRUCK']\n",
    "list_of_trucks_3 = list(set(good_trux_3))\n",
    "valid_trucks_o = [x for x in list_of_trucks_3 if (x >= 1 | x < 9999)]\n",
    "len(valid_trucks_o)\n",
    "#418"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# This block creates a list of truck IDs as numeric values (valid_trucks).\n",
    "\n",
    "#good_trux = trans_f_df['TRNUNT'].str.extract('(\\d+)')\n",
    "#list_of_trucks = list(set(good_trux))\n",
    "#num_trux = pd.to_numeric(list_of_trucks, downcast='integer')\n",
    "#valid_trucks_t = [x for x in num_trux if np.isnan(x) != True]\n",
    "#print(valid_trucks_t)\n",
    "\n",
    "good_trux_2 = event_f_df['EquipmentID']\n",
    "list_of_trucks_2 = list(set(good_trux_2))\n",
    "valid_trucks_e = [x for x in list_of_trucks_2 if (x >= 1 | x < 9999)]\n",
    "len(valid_trucks_e)\n",
    "#327"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block creates a list of driver codes.\n",
    "\n",
    "good_driv = trans_f_df['TRNDRI'].str.extract('(\\S+)')\n",
    "list_of_drivs = list(set(good_driv))\n",
    "valid_driv_t = [x for x in list_of_drivs if str(x) != 'nan']\n",
    "\n",
    "len(valid_driv_t)\n",
    "#938"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transaction codes for fuel transactions\n",
    "trx_list = ['ULSD', 'FUEL', 'CDSL', 'DEFC', 'DSL1', 'BDSL']\n",
    "df_fuel_trans = trans_f_df[trans_f_df['TRNPI1'].isin(trx_list)]\n",
    "# We don't need the TRNPI 2-6 column since they do not contain any valid fuel item (I have checked them \n",
    "# but the queries are not here.)\n",
    "df_fuel_trans = df_fuel_trans.drop(['TRNPI2','TRNPI3','TRNPI4','TRNPI5','TRNPI6','TRNPQ2','TRNPQ3',\\\n",
    "                                    'TRNPQ4','TRNPQ5','TRNPQ6'], axis=1)\n",
    "df_fuel_trans = df_fuel_trans.drop(['TRNID','TRNDAT','TRNTIM','TRNTS#','TRNTSN','TRNSTC','TRNST', 'TRNPI1'], axis=1)\n",
    "df_fuel_trans.head(5)\n",
    "df_fuel_trans.shape\n",
    "# (104057, 3)\n",
    "#df_fuel_trans = df_fuel_trans[df_fuel_trans.TRNDRI.isin(valid_driv_t)]\n",
    "#df_fuel_trans.shape\n",
    "#df_fuel_trans = df_fuel_trans[df_fuel_trans.TRNUNT.isin(valid_trucks_e)]\n",
    "#df_fuel_trans.shape\n",
    "#df_fuel_trans = df_fuel_trans[(df_fuel_trans.TRNDRI.isin(valid_driv_t) == True) & (df_fuel_trans.TRNUNT.isin(valid_trucks_e) == True)]\n",
    "\n",
    "\n",
    "#df_fuel_trans.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this converts blanks to string and then strip will make it a Nan and then it can be removed\n",
    "df_fuel_trans['TRNUNT'] = df_fuel_trans['TRNUNT'].apply(str)\n",
    "df_fuel_trans['TRNUNT'] = df_fuel_trans['TRNUNT'].str.strip()\n",
    "df_fuel_trans['TRNDRI'] = df_fuel_trans['TRNDRI'].apply(str)\n",
    "df_fuel_trans['TRNDRI'] = df_fuel_trans['TRNDRI'].str.strip()\n",
    "df_fuel_trans.isnull().values.any()\n",
    "print(df_fuel_trans['TRNUNT'].dtype)\n",
    "print(df_fuel_trans['TRNDRI'].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#This gets us a compact df with driver, truck and fuel level across all fuel transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df_fuel_by_truck_driver = df_fuel_trans.groupby(['TRNDRI','TRNUNT'], as_index=False)['TRNPQ1'].sum()\n",
    "#df_fuel_by_truck_driver['TRNDRI'].replace('', np.nan, inplace=True)   \n",
    "#df_fuel_by_truck_driver['TRNUNT'].replace('', np.nan, inplace=True)\n",
    "#df_fuel_by_truck_driver.dropna(axis=0, how='any')\n",
    "#df_fuel_by_truck_driver = df_fuel_by_truck_driver[~(df_fuel_by_truck_driver[['TRNDRI']] == '').any(axis=1)]\n",
    "#df_fuel_by_truck_driver = df_fuel_by_truck_driver[df_fuel_by_truck_driver['TRNDRI'].notnull() & df_fuel_by_truck_driver['TRNUNT'].notnull()]\n",
    "df_fuel_by_truck_driver = df_fuel_by_truck_driver.rename(columns={'TRNDRI':'DriverID', 'TRNUNT':'EquipmentID', \\\n",
    "                                                                  'TRNPQ1':'fuel'})\n",
    "df_fuel_by_truck_driver.head()\n",
    "#df_fuel_by_truck_driver = df_fuel_by_truck_driver.reset_index()\n",
    "\n",
    "#df_fuel_by_truck_driver = df_fuel_by_truck_driver.reset_index()\n",
    "#df_fuel_by_truck_driver.info()\n",
    "df_fuel_by_truck_driver.head()\n",
    "#df.groupby(['Country', 'Item_Code'])[[\"Y1961\", \"Y1962\", \"Y1963\"]].sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "event_f_df.head(3)\n",
    "\n",
    "# Id                AutoNumber ID                                                   [EV]\n",
    "# ESS_Id            Omnitracs Event Subscriber Service Event Id\n",
    "# EventTimeStamp    DateTime of Event (normalized to Central Time)\n",
    "# EquipmentID       Unit Number                                                     [TU] (?)\n",
    "# MCTNumber         Mobile Communications Terminal ID\n",
    "# EquipmentType     should always read ‘tractor’\n",
    "# DriverId          Driver Code Assigned to unit at time of reading (varchar(6))    [DR] (?)\n",
    "# Latitude          decimal degrees latitude at time of reading\n",
    "# Longitude         decimal degrees longitude at time of reading\n",
    "# LocationTimeStamp DateTime of location reading\n",
    "# Speed             MPH at time of reading\n",
    "# Heading           direction of travel at time of reading\n",
    "# Odometer          unit odometer at time of reading\n",
    "# IgnitionStatus    1=on, 2=off\n",
    "# EFReportReason    0=ignition on, 1=ignition off, 2=timer\n",
    "\n",
    "# NOTE: Discard equipment IDs that are wrongfully replaced by MCTNumber\n",
    "event_f_df.shape\n",
    "#(8495130, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many truck events for each truck??\n",
    "df_events_trucks = event_f_df[~(event_f_df[['Odometer']] == 0).any(axis=1)]\n",
    "\n",
    "#df_events_truck = df_events_truck.EquipmentID.value_counts().sort_values(ascending=False)\n",
    "#df_events_truck = pd.DataFrame(data=df_events_truck)\n",
    "#df_events_truck = df_events_truck.reset_index();\n",
    "#df_events_truck.columns = ['EquipmentID','Count']\n",
    "#df_events_truck.head()\n",
    "df_events_trucks.head()\n",
    "df_events_trucks.shape\n",
    "#df_events_trucks.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the miles travelled by driver truck combination\n",
    "df_events_trucks['DriverID'] = df_events_trucks['DriverID'].apply(str)\n",
    "df_events_trucks['EquipmentID'] = df_events_trucks['EquipmentID'].apply(str)\n",
    "df_events_trucks['DriverID'] = df_events_trucks['DriverID'].str.strip()\n",
    "df_events_trucks['EquipmentID'] = df_events_trucks['EquipmentID'].str.strip()\n",
    "\n",
    "df_events_trucks.isnull().values.any()\n",
    "print(df_events_trucks['DriverID'].dtype)\n",
    "print(df_events_trucks['EquipmentID'].dtype)\n",
    "\n",
    "df_mileage = pd.DataFrame()\n",
    "df_mileage['lowest'] = df_events_trucks.groupby(['DriverID','EquipmentID'])['Odometer'].min()\n",
    "df_mileage['highest'] = df_events_trucks.groupby(['DriverID','EquipmentID'])['Odometer'].max()\n",
    "df_mileage['miles'] = (df_mileage['highest'] - df_mileage['lowest'])\n",
    "\n",
    "df_mileage.dropna()\n",
    "df_mileage = df_mileage.reset_index()\n",
    "df_mileage.head()\n",
    "#df_mileage.info()\n",
    "#filtered_data = df[df.topping == 'pineapple']\n",
    "great_driver_list = ['SMID', 'BEVL', 'RICS', 'NEWR', 'MARC', 'LOVH']\n",
    "#df_mileage[df_mileage.DriverID.isin(great_driver_list)]\n",
    "#df_mpg.loc[df_mpg['DriverID'] =='LOVH',:]  \n",
    "#filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df_mileage[df_mileage.DriverID.isin(great_driver_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df_mileage.head()\n",
    "#df_mileage.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df_fuel_by_truck_driver.head()\n",
    "#df_fuel_by_truck_driver.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_mileage[df_mileage.DriverID.isin(great_driver_list)]\n",
    "\n",
    "\n",
    "df_fuel_by_truck_driver['DriverID'] = df_fuel_by_truck_driver['DriverID'].apply(str)\n",
    "df_mileage['DriverID'] = df_mileage['DriverID'].apply(str)\n",
    "df_fuel_by_truck_driver['EquipmentID'] = df_fuel_by_truck_driver['EquipmentID'].apply(str)\n",
    "df_mileage['EquipmentID'] = df_mileage['EquipmentID'].apply(str)\n",
    "\n",
    "\n",
    "\n",
    "#df_merged = pd.merge(df_mileage, df_fuel_by_truck_driver,  on=['DriverID','EquipmentID'], how='inner')\n",
    "df_merged = pd.merge(df_mileage, df_fuel_by_truck_driver, left_on=['DriverID','EquipmentID'], right_on=['DriverID','EquipmentID'], how='inner')\n",
    "#print(pd.merge(df1,df2, on=['HPI','Int_rate']))\n",
    "\n",
    "#df_merged[df_merged.DriverID.isin(great_driver_list)]\n",
    "\n",
    "df_merged.head()\n",
    "#df_merged.info()\n",
    "#df_merged.shape\n",
    "#(2981, 7)\n",
    "#df_merged.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged['mpg'] = df_merged['miles']/df_merged['fuel']\n",
    "df_mpg = df_merged[(df_merged['mpg'] > 3) & (df_merged['mpg'] < 10)]\n",
    "df_mpg.head()\n",
    "#df_merged.shape\n",
    "#df_mpg.describe()\n",
    "#df_merged.DriverID.value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bins = 20\n",
    "n, bins, patches = plt.hist(df_mpg.mpg, num_bins, facecolor='blue', alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a classification based on mpg. Good > 7, Avergage 5.5-7 and Bad < 5.5\n",
    "df_mpg['class'] = np.where(df_mpg['mpg']>7, 'Good', 'Avergage')\n",
    "#df_mpg['class'] = np.where((df_mpg['mpg'] >= 5.5) & (df_mpg['mpg'] < 7), 'Average', 'Bad')\n",
    "df_mpg['class'] = np.where((df_mpg['mpg'] < 5.5) , 'Bad', 'Average')\n",
    "#df['elderly'] = np.where(df['age']>=50, 'yes', 'no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mpg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_driver(row):\n",
    "    if row['mpg'] >= 7:\n",
    "        val = 'Good'\n",
    "    elif row['mpg'] >= 5.5:\n",
    "        val = 'Average'\n",
    "    else:\n",
    "        val = 'Bad'\n",
    "    return val\n",
    "\n",
    "df_mpg['class'] = df_mpg.apply(classify_driver, axis=1)\n",
    "df_mpg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#num_bins = 3\n",
    "#n, bins, patches = plt.hist(df_mpg.class, num_bins, facecolor='blue', alpha=0.5)\n",
    "#plt.show()\n",
    "df_mpg['class'].value_counts().plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mpg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot data with seaborn\n",
    "facet = sns.lmplot(data=df_mpg, x='EquipmentID', y='mpg', hue='class', \n",
    "                   fit_reg=False, legend=True, legend_out=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bplot = sns.boxplot(y='mpg', x='class', data = df_mpg, width=0.8, palette=\"colorblind\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.loc[df['column_name'] == some_value]\n",
    "#print(df_mpg.loc[df_mpg['DriverID']=='BEVL'])\n",
    "df_mpg[df_mpg.DriverID =='MARC']\n",
    "#df_mpg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Great Drivers list for comparison and setting values of class\n",
    "driver_list = ['SMID', 'BEVL', 'RICS', 'NEWR', 'MARC', 'LOVH']\n",
    "#filtered_data = df_mileage[df_mileage.DriverID == 'MARC']\n",
    "#driver_list = {'SMID':'Great', 'BEVL':'Great', 'RICS':'Great', 'NEWR':'Great', 'MARC':'Great', 'LOVH':'Great'}\n",
    "#df_mpg['class'] = np.where[df_mpg['DriverID'].isin(driver_list), 'Great', df_mpg['class']]\n",
    "#np.where(df_mpg['mpg']>7, 'Good', 'Avergage')\n",
    "#df_mpg.head()\n",
    "#d = {'NONANE':9, 'OCTANE':8, 'HEPTANE':7, 'HEXANE':6}\n",
    "#df['num'] = df['solvent'].map(d)\n",
    "#df_mpg.loc[df_mpg['DriverID'].isin(driver_list), 'Class'] = 'Great'\n",
    "df_mpg.loc[df_mpg.DriverID == 'SMID', 'class'] = 'Great'\n",
    "df_mpg.loc[df_mpg['DriverID'] == 'BEVL', 'class'] = 'Great'\n",
    "df_mpg.loc[df_mpg['DriverID'] == 'RICS', 'class'] = 'Great'\n",
    "df_mpg.loc[df_mpg['DriverID'] == 'NEWR', 'class'] = 'Great'\n",
    "df_mpg.loc[df_mpg['DriverID'] == 'MARC', 'class'] = 'Great'\n",
    "df_mpg.loc[df_mpg['DriverID'] == 'LOVH', 'class'] = 'Great'\n",
    "#df_mpg.loc[df_mpg['Class'] == 'Great']\n",
    "df_mpg.describe()\n",
    "#df_mpg.loc['Class'] = df_mpg['DriverID'].map(driver_list)\n",
    "#df_mpg.head(100)\n",
    "#df_mpg.loc[df_mpg['DriverID'].isin(driver_list), :]\n",
    "df_mpg.head()\n",
    "df_mpg[df_mpg.DriverID == 'MARC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.set(color_codes=True)\n",
    "sns.distplot(df_mpg.mpg);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mpg['class'].value_counts().plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw a categorical scatterplot to show each observation\n",
    "sns.set(style=\"whitegrid\", palette=\"muted\")\n",
    "sns.swarmplot(x=\"class\", y=\"mpg\", hue=\"class\", data=df_mpg)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting Fraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find bad mpg drivers\n",
    "df_bad_drivers = df_mpg[df_mpg['class'] == 'Bad']\n",
    "#filtered_data = df[df.topping == 'pineapple']\n",
    "df_bad_drivers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(event_f_df, level_f_df, how='inner', left_on=['Id'], right_on = ['ExactFuelEventId'])\n",
    "dfs = df[['EventTimeStamp', 'EquipmentID', 'DriverID', 'Odometer','IgnitionStatus','TankLevelGallons']]\n",
    "# calculate fuel difference between each set of rows\n",
    "dfs = dfs[(dfs['DriverID'] == 'BUNC') & (dfs['IgnitionStatus'] == 2)]\n",
    "\n",
    "dfs = dfs.sort_values(by=['EventTimeStamp','EquipmentID','DriverID','Odometer'])\n",
    "\n",
    "#dfs['odo_diff'] = dfs['Odometer'].shift(-1) -  dfs['Odometer']\n",
    "dfs['odo_diff'] = dfs['Odometer'].diff()\n",
    "dfs['fuel_diff'] = dfs['TankLevelGallons'].diff()\n",
    "dfs.loc[dfs.EquipmentID != dfs.EquipmentID.shift(), 'odo_diff'] = 0\n",
    "dfs.loc[dfs.EquipmentID != dfs.EquipmentID.shift(), 'fuel_diff'] = 0\n",
    "\n",
    "\n",
    "dfs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_doubt = dfs[(dfs['odo_diff'] == 0) & (dfs['fuel_diff'] < -1)]\n",
    "df_doubt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dq = dfs[(dfs['Odometer'] == 203784.3) ]\n",
    "dq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the function regplot to make a scatterplot\n",
    "sns.regplot(x=dq[\"Odometer\"], y=dq[\"fuel_diff\"])\n",
    "plt.show()\n",
    " \n",
    "# Without regression fit:\n",
    "#sns.regplot(x=dfs[\"Odometer\"], y=dfs[\"TankLevelGallons\"], fit_reg=False)\n",
    "#sns.plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Downsizing the databases\n",
    "To do this, we eliminate all drivers/trucks that have invalid syntax, followed by reducing the databases that contain these elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Here all the valid drivers and trucks are inner-joined (intersected), to be used for downsizing the database.\n",
    "\n",
    "valid_driv = [x for x in valid_driv_t if (x in valid_driv_e)]\n",
    "\n",
    "# 2 step inner join for tricks\n",
    "valid_truck = [x for x in valid_trucks_e if (x in valid_trucks_o)]\n",
    "valid_trux = [x for x in valid_truck if (x in valid_trucks_t)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Downsizing dataframes take place here.\n",
    "\n",
    "# optimization\n",
    "optim_f_df_ds = optim_f_df[optim_f_df.TRUCK.isin(valid_trux) == True]\n",
    "# events\n",
    "event_f_df_ds = event_f_df[(event_f_df.EquipmentID.isin(valid_trux) == True) & (event_f_df.DriverID.isin(valid_driv) == True)]\n",
    "# Transactions\n",
    "trans_f_df['numtruc'] = pd.to_numeric(trans_f_df['TRNUNT'], errors='coerce')\n",
    "trans_f_df_ds = trans_f_df[(trans_f_df.TRNDRI.isin(valid_driv) == True) & (trans_f_df.numtruc.isin(valid_trux) == True)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fraudulent Transaction Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_fraud = pd.merge(event_f_df, level_f_df, how='inner', left_on=['Id'], right_on = ['ExactFuelEventId'])\n",
    "#df_merged = pd.merge(df_mileage, df_fuel_by_truck_driver, on=['DriverID','EquipmentID'])\n",
    "#new_df = pd.merge(A_df, B_df,  how='left', left_on=['A_c1','c2'], right_on = ['B_c1','c2'])\n",
    "df_fraud.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging data sets and cleaning columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merge database\n",
    "fuel_trak_df = pd.merge(event_f_df_ds, level_f_df, how='inner', left_on='Id', right_on='ExactFuelEventId')\n",
    "# discard duplicate columns\n",
    "fuel_trak_df = fuel_trak_df.drop(['Id_x','Id_y'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Columns added to allocate differences in nextcoming steps\n",
    "\n",
    "fuel_trak_df = fuel_trak_df.assign(dif_Speed=\"\")\n",
    "fuel_trak_df = fuel_trak_df.assign(dif_ODO=\"\")\n",
    "fuel_trak_df = fuel_trak_df.assign(dif_tanklevel=\"\")\n",
    "fuel_trak_df = fuel_trak_df.assign(dif_tankperc=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(len(valid_trux), len(list(set(fuel_trak_df.EquipmentID))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "level_f_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "level_f_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fuel_trak_df.sort_values(by = 'EventTimeStamp', axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Dictionary\n",
    " Fuel Analysis Project\n",
    " \n",
    "###### BGETCHDATA.PTCHTRANH\n",
    "\n",
    "1.\tTRNID\t\tTransaction ID \n",
    "2.\tTRNDAT\t    Transaction Date (YYYYMMDD)\n",
    "3.\tTRNTIM\t\tTransaction Time (HHMM)\n",
    "4.\tTRNTS#\t\tStation ID\n",
    "5.\tTRNTSN\t\tStation Name\n",
    "6.\tTRNSTC\t\tStation City\n",
    "7.\tTRNST\t\tStation State\n",
    "8.\tTRNDRI\t\tDriver Code\n",
    "9.\tTRNUNT\t    Unit ID\n",
    "10.\tTRNPI1\t\tItem Code 1\n",
    "11.\tTRNPQ1\t    Item Quantity 1\n",
    "12.\tTRNPI2\t\tItem Code 2\n",
    "13.\tTRNPQ2\t    Item Quantity 2\n",
    "14.\tTRNPI3\t\tItem Code 3\n",
    "15.\tTRNPQ3\t    Item Quantity 3\n",
    "16.\tTRNPI4\t\tItem Code 4\n",
    "17.\tTRNPQ4\t    Item Quantity 4\n",
    "18.\tTRNPI5\t\tItem Code 5\n",
    "19.\tTRNPQ5\t    Item Quantity 5\n",
    "20.\tTRNPI6\t\tItem Code 6\n",
    "21.\tTRNPQ6      Item Quantity 6\n",
    "\n",
    "Actual fuel transactions will have an item code of ULSD or FUEL, CDSL, DSL1, BDSL, and could be in any of the Item slots 1-6\n",
    " \n",
    "\n",
    "###### IBGEFILE.UNITS\n",
    "\n",
    "1.\tUNUNIT\tUnit Number\n",
    "2.\tUNYEAR\tModel Year\n",
    "3.\tUNMAKE\tMake\n",
    "4.\tUNSER\tVIN\n",
    "\n",
    "###### BGEIDSC.EF2EFFP\n",
    "\n",
    "1.\tTRUCK\t\tUnit Number\n",
    "2.\tACTIVE\t\tActive Flag (for fuel optimization)\n",
    "3.\tSENDFUEL\tSend Fuel Flag (for fuel optimization)\n",
    "4.\tSENDROUTE\tSend Route Flag (for fuel optimization)\n",
    "5.\tTANKCAP\t    Tank Capacity (gallons)\n",
    "6.\tAVGMPG\t    MPG used for Fuel optimization (real value is closer to 7mpg)\n",
    "\n",
    "###### Extranet2.ExactFuelEvent\n",
    "\n",
    "1.\tId\t\t\t    AutoNumber ID\n",
    "2.\tESS_Id\t\t\tOmnitracs Event Subscriber Service Event Id\n",
    "3.\tEventTimeStamp\tDateTime of Event (normalized to Central Time)\n",
    "4.\tEquipmentID\t\tUnit Number\n",
    "5.\tMCTNumber\t\tMobile Communications Terminal ID\n",
    "6.\tEquipmentType\tshould always read ‘tractor’\n",
    "7.\tDriverId\t\tDriver Code Assigned to unit at time of reading (varchar(6))\n",
    "8.\tLatitude\t\tdecimal degrees latitude at time of reading\n",
    "9.\tLongitude\t\tdecimal degrees longitude at time of reading\n",
    "10.\tLocationTimeStamp \tDateTime of location reading\n",
    "11.\tSpeed\t\t\tMPH at time of reading\n",
    "12.\tHeading\t\t    direction of travel at time of reading\n",
    "13.\tOdometer\t\tunit odometer at time of reading\n",
    "14.\tIgnitionStatus\t1=on, 2=off\n",
    "15.\tEFReportReason\t0=ignition on, 1=ignition off, 2=timer\n",
    "\n",
    "###### Extranet2.ExactFuelTankLevel\n",
    "\n",
    "1.\tId\t\t\t        AutoNumber id\n",
    "2.\tTankId\t\t\t    Tank Sensor # (for our trucks, will always be 1)\n",
    "3.\tTankLevelPercent\tPercentage Reading 0-100.00\n",
    "4.\tTankLevelGallons\tGallons (Percentage * Tank Capacity) (calculated)\n",
    "5.\tExactFuelEventId\tForeign Key to ExactFuelEvent\n",
    "\n",
    "##### Extranet2.QCPerformanceExtracts\n",
    "See Mary's post on slack \n",
    "https://nashvillesoftware.slack.com/files/U71DCPYBX/FAF8Q7JSZ/screen_shot_2018-04-28_at_9.03.29_am.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# STEPS TO TAKE\n",
    "+ Identify invalid Trucks/Driver names\n",
    "+ Convert into valid syntax (numeric etc)\n",
    "+ Make an intersection of all Trucks & Drivers and create a final list of good IDs for trucks and drivers\n",
    "+ Extract records with only \"good\" IDs (downsizing the database)\n",
    "+ Merge dataframes (subject to discussion)\n",
    "+ Added extra columns for allocating differences\n",
    "+ Sort By time\n",
    "\n",
    "TO DO:\n",
    "- Write a FOR loop to \n",
    "    a. filter the dataframe by each truck\n",
    "    b. calculate the differences and allocate them in columns (calculate shift)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
